\paragraph{Cognitive architectures.} This thesis falls into the category of cognitive architectures and the integrated approach to AI, pioneered by people like Rodney Brooks and his subsumption architecture, and \cite{brooksSubsumption}, Douglas Hofstaedter, who famously wrote about many aspects of AI in GÃ¶del, Escher, Bach \cite{geb}, and who created the Copycat analogy-making program \cite{copycat}. Another important work is the Hierarchical Control System of James Albus \cite{albusHCS}, in which cognitive tasks are organized hierarchically and delegated by nodes on higher levels to those on lower ones (this is similar to the mesh-like organisation of components described in Section~\ref{sec:mathematicalModel}, and to the layered structure of Minsky's {\em The Emotion Machine} \cite{emotionMachine}). The organisation described by Albus \cite{albus93areference} is, moreover, very similar to the one in Section~\ref{sec:proposedArchitecture}, with world simulator, belief generator, sensory perception, and knowledge base (herein called ``memory'') modules being mostly analogous. Another large and notionally similar system is Carnegie-Mellon's 4CAPS \cite{4caps}, which posits small, relatively simple components, individually doing simple tasks, and having only limited computational resources. Most of 4CAPS's stated principles can be recognized in the coming sections \cite[Operating Principles of 4CAPS]{4caps}:
\begin{quote}
	\begin{enumerate}
		\setcounter{enumi}{-1}
		\item Thinking is the product of the concurrent activity of multiple brain areas that collaborate in a large-scale cortical network. \ellipses
		\item Each cortical area can perform multiple cognitive functions, and conversely, many cognitive functions can be performed by more than one area.
		\item Each cortical area has a limited capacity of computational resources, constraining its activity.
		\item The topology of a large-scale cortical network changes dynamically during cognition, adapting itself to the resource limitations of different cortical areas and to the functional demands of the task at hand.
		\item The communications infrastructure that supports collaborative processing is also subject to resource constraints, construed here as bandwidth limitations.
	\end{enumerate}
	
	\quad\quad\ \ellipses
\end{quote}

The probably earliest example of a cognitive architecture was Allen Newell's and Herbert~A.~Simon's {\em Logic Theorist}, created in 1955 \cite[p. 44]{crevier93}. Simon's theory of bounded rationality \cite{Gigerenzer2001} --- the idea of finding a merely satisfactory solution instead of a (provably) optimal one --- is very similar to the loop between belief generation and evaluation described in Section~\ref{sec:implementation}. In both cases, agents with limited information search heuristically for the first solution that they find acceptable. Unlike exhaustive search methods (e.g. A*), this does not guarantee the best possible results, but it is much more cost-effective and closer to the way real humans solve problems. In spirit, this is also similar to the {\em Procedural Reasoning System} of Michael Georgeff et al. \cite{pcs}, which is based on the belief-desire-intention model \cite{Rao95bdiagents, Bratman87}. Much theoretical work has been done on BDI, but it is only tangentially related to this thesis.

\paragraph{Sloman.} Many of the fundamental ideas in this thesis can be found in Alan Sloman's works \cite{sloman1993, sloman1997, sloman1999, sloman2000, slomanSimAgent}, especially in {\em Beyond shallow models of emotion}. Therein, he formulated the crtierion of evolvability in the context of cognitive architectures and postulated the possibility that nervous systems may be chaotic (but not unorganized). The agent architecture in Section~\ref{sec:implementation} substantially resembles his, though it was not taken from there. The similarity is, however, indicative of a great deal of shared thought.

\paragraph{Implementation.} In terms of software engineering, our model has similarities, both to the Actor model \cite{hewittActor}, and to publish/subscribe architectures \cite{publishSubscribe} --- although more as a concession to practicality and less because of a similarity to their theories. The theoretical basis of our implementation is the postulate that the components of the brain function as white boxes and that other components may listen in on their activity, so to speak. Since this is diametrically opposed to the traditional idea of the procedure/function as a black box, which nigh every programming language follows, we compromise and model the cognitive structure as a mesh of loosely coupled components communicating via passing. This description is reminiscent to the Actor model developed by Carl Hewitt et al. , although there are differences\footnote{Although we do not describe the implementation in the language of the Actor model, a translation into it would be quite easy. Such a translation would require using only very rudimentary features of the model, however, and, as that is not the focus, we forego the task.}: in the Actor model, the topology of the network may change through the creation of new actors, and messages are always passed from one source to known targets (via addresses). In our model, on the other hand, there is no topology in a strict sense; messages are put into a global message storage and every component is free to consume any message it deems relevant. Senders do not know who will read their output, and consumers do not know the sources. This arrangement can be seen as a particularly loose variant of a publish/subscribe architecture, in which the source and the target of a message are completely unaware of each other, and in which there are no specific channels to which one may subscribe. The only criterion by which messages may be accepted or rejected is their content.

% We also make use of already existing solutions --- specifically answer-set programming and the \acthex\ solver \dlvhex. The internal world simulation of our agents makes use of the non-monotonic reasoning provided by ASP and \acthex.  Answer-set programming was created by Gelfond and Lifschitz \cite{asp1}. Soon after them, Subrahmanian made the connection between ASP and planning \cite{Subrahmanian95relatingstable}. Together with Eiter and others, he later developed the \acthex\ language which allowed provided a framework for decision making in logic programming via external input and output atoms \cite{heterogeneous1, heterogeneous2, heterogeneous3}.

\paragraph{Nouvelle AI.} Lastly, the overall goal, if not the method, of this thesis echoes that of the {\em nouvelle AI} of, again, Brooks, who claims that
\begin{quotation}
	the Von Neumann model of computation has lead Artificial Intelligence in particular directions. Intelligence in biological systems is completely different. \cite{Brooks91intelligencewithout}
\end{quotation}
The nouvelle AI approach stands in contrast to traditional AI in that it does not aim for human-level performance at specific tasks, but rather for the faithful reproduction of the behaviour of lower animals like dogs \cite{nouvelleAI}. Brooks might be closer to the biological realities in his desire to abandon the von Neumann model in favour of biologically modelled computation, though we will only take only general inspiration from his approach, not follow it closely. As our goal is merely a proof-of-concept implementation, and since the realization of truly novel programming, biologically oriented, paradigms is quite laborious, we opted for a compromise position and only tried to imitate biological computation in general spirit rather than in every detail.